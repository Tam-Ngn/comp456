---
title: "bidenarticlesafter"
author: '" "'
date: '2023-03-22'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, error = TRUE, tidy = FALSE, message = FALSE, cache.extra = packageVersion("tufte"))
library(tidyverse)
library(dplyr)
library(lubridate)
library(urltools)
library(scales)
library(textdata)
library(wordcloud)
library(igraph) 
library(ggplot2)
library(tidytext)
library(broom)
library(reshape2)
library(rvest)
data("stop_words")
load("C:/Users/cecei/Desktop/comp465/bidenarticlesafter.RData")
mystopwords <- tibble(word = c(word = c("trump", "trumps", "trump's","trump’s", "biden", "biden's", "biden’s", "donald", "u.s", "joe", "elizabeth", "warren", "here's", "sanders", "joseph", "it's", "here's", "jr", "vice")))
```



```{r}
biden <- bidenarticlesafter %>% 
  unnest(headline) %>% 
  select(abstract, snippet, lead_paragraph, main, pub_date, section_name)

tidy_biden_main <- biden %>% 
  unnest_tokens(word, main) %>% 
  anti_join(stop_words) %>% 
  anti_join(mystopwords) %>% 
  count(word, sort = TRUE)

tidy_biden_main %>% 
  inner_join(get_sentiments("bing")) %>% 
  group_by(sentiment) %>% 
  slice_max(n, n = 10) %>% 
  mutate(word = reorder(word, n)) %>% 
  ggplot(aes(n, word, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(x = "Contribution to sentiment",
       y = NULL)
```



```{r}
tidy_biden_main %>%
  with(wordcloud(word, n, max.words = 50))
```


```{r}
biden_mix <- tibble(word = paste(bidenarticlesafter$abstract, 
                                 bidenarticlesafter$snippet, 
                                 bidenarticlesafter$lead_paragraph, 
                                 bidenarticlesafter$headline$main))

tidy_biden_mix <- biden_mix %>% 
  unnest_tokens(word, word) %>% 
  anti_join(stop_words) %>% 
  anti_join(mystopwords) %>% 
  count(word, sort = TRUE)

tidy_biden_mix %>% 
  inner_join(get_sentiments("bing")) %>% 
  group_by(sentiment) %>% 
  slice_max(n, n = 10) %>% 
  mutate(word = reorder(word, n)) %>% 
  ggplot(aes(n, word, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(x = "Contribution to sentiment",
       y = NULL)

tidy_biden_mix %>%
  with(wordcloud(word, n, max.words = 50))
```
```{r}
section_words <- tibble(word = paste(bidenarticlesafter$abstract, 
                                     bidenarticlesafter$snippet, 
                                     bidenarticlesafter$lead_paragraph, 
                                     bidenarticlesafter$headline$main),
                        section = bidenarticlesafter$section_name) %>% 
  unnest_tokens(word, word) %>% 
  count(section, word, sort = TRUE)

tot_words <- section_words %>% 
  group_by(section) %>% 
  summarize(total = sum(n))

section_words <- left_join(section_words, tot_words, by = "section")

section_tf_idf <- section_words %>% 
  bind_tf_idf(word, section, n) %>% 
  arrange(desc(tf_idf))

section_tf_idf %>% 
  filter(section %in% c("U.S.", "Opinion", "World", "Business Day", "Podcasts")) %>% 
  group_by(section) %>% 
  slice_max(tf_idf, n = 10) %>% 
  ungroup() %>% 
  ggplot(aes(x = tf_idf, y = fct_reorder(word, tf_idf), fill = section)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~section, ncol = 2, scales = "free") +
  labs(x = "tf-idf")

```

```{r}
biden_bigrams <- tibble(word = paste(bidenarticlesafter$abstract, 
                                     bidenarticlesafter$snippet, 
                                     bidenarticlesafter$lead_paragraph, 
                                     bidenarticlesafter$headline$main),
                        section = bidenarticlesafter$section_name) %>% 
  unnest_tokens(bigram, word, token = "ngrams", n = 2) %>% 
  filter(!is.na(bigram))

biden_bigram_sep <- biden_bigrams %>% 
  separate(bigram, c("word1", "word2"), sep = " ")

section_bigram_tf_idf <- biden_bigram_sep %>% 
  filter(!word1 %in% stop_words$word) %>% 
  filter(!word1 %in% mystopwords$word) %>% 
  filter(!word2 %in% stop_words$word) %>% 
  filter(!word2 %in% mystopwords$word) %>% 
  unite(bigram, word1, word2, sep = " ") %>% 
  count(section, bigram, sort = TRUE)

section_bigram_tf_idf %>% 
  bind_tf_idf(bigram, section, n) %>% 
  arrange(desc(tf_idf)) %>% 
  filter(section %in% c("U.S.", "Opinion", "World", "Business Day", "Podcasts")) %>% 
  group_by(section) %>% 
  slice_max(tf_idf, n = 10) %>% 
  ungroup() %>% 
  ggplot(aes(x = tf_idf, y = fct_reorder(bigram, tf_idf), fill = section)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~section, ncol = 2, scales = "free") +
  labs(x = "tf-idf")

bigram_graph <- biden_bigram_sep %>% 
  filter(!word1 %in% stop_words$word) %>% 
  filter(!word1 %in% mystopwords$word) %>% 
  filter(!word2 %in% stop_words$word) %>% 
  filter(!word2 %in% mystopwords$word) %>% 
  count(word1, word2, sort = TRUE) %>% 
  filter(n > 70) %>% 
  graph_from_data_frame()

set.seed(2020)
a <- grid::arrow(type = "closed", length = unit(.15, "inches"))

ggraph(bigram_graph, layout = "fr") +
  geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
                 arrow = a, end_cap = circle(.07, 'inches')) +
  geom_node_point(color = "lightblue", size = 3) +
  geom_node_text(aes(label = name), vjust = 0.2, hjust = 0.2) +
  theme_void()
```

```{r}
biden_trigrams <- tibble(word = paste(bidenarticlesafter$abstract, 
                                      bidenarticlesafter$snippet, 
                                      bidenarticlesafter$lead_paragraph, 
                                      bidenarticlesafter$headline$main),
                        section = bidenarticlesafter$section_name) %>% 
  unnest_tokens(trigram, word, token = "ngrams", n = 3) %>% 
  filter(!is.na(trigram))

biden_trigram_sep <- biden_trigrams %>% 
  separate(trigram, c("word1", "word2", "word3"), sep = " ")

biden_trigram_sep %>% 
  filter(!word1 %in% stop_words$word) %>% 
  filter(!word1 %in% mystopwords$word) %>% 
  filter(!word2 %in% stop_words$word) %>% 
  filter(!word2 %in% mystopwords$word) %>% 
  filter(!word3 %in% stop_words$word) %>% 
  filter(!word3 %in% mystopwords$word) %>% 
  unite(trigram, word1, word2, word3, sep = " ")
```

```{r}
article <- read_html("https://www.nytimes.com/2020/12/31/us/politics/justice-department-mike-pence-louie-gohmert.html")
body_text <-
  article %>%
  html_elements(".css-at9mc1.evys1bk0") %>%
  html_text()
head(body_text)
```

