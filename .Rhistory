}
}
totalarticles2 <- NULL
totalarticles2 <- NULL
save(totalarticles, file = "trump_guardian_2020.RData")
gc()
load("trump_guardian_2020.RData")
View(totalarticles)
totalarticles2 <- NULL
library(jsonlite)
library(tidyverse)
library(lubridate)
library(rvest)
key <- "&api-key=9f51672b-1066-4b6f-a6ca-4066419d6f96"
url <- "https://content.guardianapis.com/search?q=trump&from-date=2020-01-01&to-date=2020-01-01&page=1"
req <- fromJSON(paste0(url, key))
library(jsonlite)
library(tidyverse)
library(lubridate)
library(rvest)
key <- "&api-key=9f51672b-1066-4b6f-a6ca-4066419d6f96"
url <- "https://content.guardianapis.com/search?q=trump&from-date=2020-01-01&to-date=2020-01-01&page=1"
req <- fromJSON(paste0(url, key))
totalarticles2 <- NULL
for(i in d){
p = 1
while(p < 10){
url = paste0(link, '&from-date=',i ,'&to-date=',i ,'&page=',p)
req <- try(fromJSON(paste0(url, key)),silent=TRUE)
if(class(req) == 'try-error'){ break }
else{
articles <- req$response$results
totalarticles2 <- bind_rows(totalarticles2,articles)
if(isTRUE(nrow(articles)) && nrow(articles) != 10){ break }
else{p = p+1}
}
# Sys.sleep(6)
}
}
key <- "&api-key=9f51672b-1066-4b6f-a6ca-4066419d6f96"
url <- "https://content.guardianapis.com/search?q=trump&from-date=2020-01-01&to-date=2020-01-01&page=1"
req <- fromJSON(paste0(url, key))
key <- "&api-key=395b850e-d5c2-4414-aed5-02beddcbbd23"
url <- "https://content.guardianapis.com/search?q=trump&from-date=2021-09-06&to-date=2021-09-06&page=1"
req <- fromJSON(paste0(url, key))
articles <- req$response$results
link = "https://content.guardianapis.com/search?q=trump"
dates <- ymd('20210907') + 0:116
d <- format(dates,'%Y-%m-%d')
totalarticles2 <- NULL
for(i in d){
p = 1
while(p < 10){
url = paste0(link, '&from-date=',i ,'&to-date=',i ,'&page=',p)
req <- try(fromJSON(paste0(url, key)),silent=TRUE)
if(class(req) == 'try-error'){ break }
else{
articles <- req$response$results
totalarticles2 <- bind_rows(totalarticles2,articles)
if(isTRUE(nrow(articles)) && nrow(articles) != 10){ break }
else{p = p+1}
}
# Sys.sleep(6)
}
}
View(totalarticles2)
totalarticles3 <- rbind(totalarticles, totalarticles2)
View(totalarticles3)
totalarticles <- rbind(totalarticles, totalarticles2)
totalarticles3 <- load("/Users/yiyangshi/Desktop/SPRING 2023/STAT 456/comp465/Articles Data/Guardian_Trump_Before_API.RData")
load("/Users/yiyangshi/Desktop/SPRING 2023/STAT 456/comp465/Articles Data/Guardian_Trump_Before_API.RData")
View(g_t_aug2019_jun2020)
totalarticles <- rbind(totalarticles, g_t_aug2019_jun2020)
View(totalarticles)
save(totalarticles, file = "trump_guardian.RData")
load("trump_guardian.RData")
View(totalarticles)
article <- NULL
body_text_tot <- NULL
for (i in 1:length(totalarticles$webUrl)) {
article <- read_html(totalarticles$webUrl[i])
body_text <-
article %>%
html_elements(".dcr-n6w1lc") %>%
html_text()
body_text_coll<- tibble(url = totalarticles$webUrl[i], text = paste(body_text, collapse = " "))
body_text_tot <- bind_rows(body_text_tot, body_text_coll)
}
View(body_text_tot)
knitr::opts_chunk$set(echo = TRUE, error = TRUE, tidy = FALSE, message = FALSE, cache.extra = packageVersion("tufte"))
library(tidyverse)
library(dplyr)
library(lubridate)
library(urltools)
library(scales)
library(textdata)
library(wordcloud)
library(igraph)
library(ggplot2)
library(tidytext)
library(broom)
library(reshape2)
library(rvest)
library(igraph)
library(tm)
library(ggraph)
data("stop_words")
mystopwords <- tibble(word = c("trump", "trumps", "trump's","trump’s", "biden", "biden's", "biden’s", "donald", "u.s", "joe", "elizabeth", "warren", "here/'s", "sanders", "joseph", "it/'s", "here's", "jr", "vice", "bernie", "obama", "hampshire", "thursday", "tuesday", "bloomberg", "ms", "gail", "bret", "dr", "buttigieg"))
load("Guardian_Trump_Before_API.RData")
library(jsonlite)
library(tidyverse)
library(lubridate)
library(rvest)
key <- "&api-key=CunYbsfgJWDXmpfcvKnoW1G3TBAY6grG"
url <- "https://api.nytimes.com/svc/search/v2/articlesearch.json?q=trump&begin_date=20200101&end_date=20200101&page=1"
req <- fromJSON(paste0(url, key))
articles <- req$response$docs
link = "https://api.nytimes.com/svc/search/v2/articlesearch.json?q=trump"
keys <- c("&api-key=CunYbsfgJWDXmpfcvKnoW1G3TBAY6grG",
"&api-key=gDxQ32ZZfP8KarCN5MrGdmrkeKfkko7u",
"&api-key=Cg6eP60vTxQAEtZoez9YccqiF9CHCyCA",
"&api-key=9fiVSl9AtqEaHqtInQLx3V56dmUgYy27",
"&api-key=kfpVf3ML5uymHzA83Ai5op7AZfQbkjcB",
"&api-key=dfrzINL05mURMbUrnLDGgsNWBlAqVR9n")
dates <- ymd('20200101') + 0:5
d <- format(dates,'%Y%m%d')
totalarticles <- NULL
# for (i in 1:length(keys)) {
#   key = keys[i]
#   for(i in d){
#     p = 0
#     while(p < 10){
#       url = paste0(link, '&begin_date=',i ,'&end_date=',i ,'&page=',p)
#       req <- fromJSON(paste0(url, key))
#       articles <- req$response$docs
#       totalarticles <- bind_rows(totalarticles,articles)
#       if(isTRUE(nrow(articles)) && nrow(articles) != 10){ break }
#       else{p = p+1}
#       Sys.sleep(12)
#     }
#   }
# }
pr = 0
for(i in d){
p = 0
while(p < 10){
key <- keys[pr %% length(keys)+1] #modular arithmetic
#key <- sample(keys, size = 1)
url = paste0(link, '&begin_date=',i ,'&end_date=',i ,'&page=',p)
req <- fromJSON(paste0(url, key))
pr = pr + 1
articles <- req$response$docs
totalarticles <- bind_rows(totalarticles,articles)
if(is.null(nrow(articles)) | (isTRUE(nrow(articles)) && nrow(articles) != 10)){ break }
else{p = p+1}
Sys.sleep(2)
}
}
totalarticles <-  totalarticles %>%
mutate(date = str_trunc(webPublicationDate, width = 10, ellipsis = "")) %>%
filter(date >= "2020-01-01")
load("~/Documents/GitHub/comp456/Articles Data/bidenarticles.RData")
View(bidenarticles)
library(jsonlite)
library(tidyverse)
library(lubridate)
library(rvest)
key <- "&api-key=CunYbsfgJWDXmpfcvKnoW1G3TBAY6grG"
url <- "https://api.nytimes.com/svc/search/v2/articlesearch.json?q=trump&begin_date=20200101&end_date=20200101&page=1"
req <- fromJSON(paste0(url, key))
articles <- req$response$docs
link = "https://api.nytimes.com/svc/search/v2/articlesearch.json?q=trump"
keys <- c("&api-key=CunYbsfgJWDXmpfcvKnoW1G3TBAY6grG",
"&api-key=gDxQ32ZZfP8KarCN5MrGdmrkeKfkko7u",
"&api-key=Cg6eP60vTxQAEtZoez9YccqiF9CHCyCA",
"&api-key=9fiVSl9AtqEaHqtInQLx3V56dmUgYy27",
"&api-key=kfpVf3ML5uymHzA83Ai5op7AZfQbkjcB",
"&api-key=dfrzINL05mURMbUrnLDGgsNWBlAqVR9n")
dates <- ymd('20200101') + 0:5
d <- format(dates,'%Y%m%d')
totalarticles <- NULL
# for (i in 1:length(keys)) {
#   key = keys[i]
#   for(i in d){
#     p = 0
#     while(p < 10){
#       url = paste0(link, '&begin_date=',i ,'&end_date=',i ,'&page=',p)
#       req <- fromJSON(paste0(url, key))
#       articles <- req$response$docs
#       totalarticles <- bind_rows(totalarticles,articles)
#       if(isTRUE(nrow(articles)) && nrow(articles) != 10){ break }
#       else{p = p+1}
#       Sys.sleep(12)
#     }
#   }
# }
pr = 0
for(i in d){
p = 0
while(p < 10){
key <- keys[pr %% length(keys)+1] #modular arithmetic
#key <- sample(keys, size = 1)
url = paste0(link, '&begin_date=',i ,'&end_date=',i ,'&page=',p)
req <- fromJSON(paste0(url, key))
pr = pr + 1
articles <- req$response$docs
totalarticles <- bind_rows(totalarticles,articles)
if(is.null(nrow(articles)) | (isTRUE(nrow(articles)) && nrow(articles) != 10)){ break }
else{p = p+1}
Sys.sleep(2)
}
}
totalarticles <-  totalarticles %>%
mutate(date = str_trunc(pub_date, width = 10, ellipsis = "")) %>%
filter(date >= "2020-01-01")
# save(totalarticles, file = "trump_guardian.RData")
article <- NULL
body_text_tot <- NULL
for (i in 1:length(totalarticles$webUrl)) {
article <- read_html(totalarticles$webUrl[i])
body_text <-
article %>%
html_elements(".css-at9mc1.evys1bk0") %>%
html_text()
body_text_coll<- tibble(url = totalarticles$webUrl[i], text = paste(body_text, collapse = " "))
body_text_tot <- bind_rows(body_text_tot, body_text_coll)
}
library(jsonlite)
library(tidyverse)
library(lubridate)
library(rvest)
library(readxl)
library(jsonlite)
library(tidyverse)
library(lubridate)
library(rvest)
library(readxl)
key <- "&api-key=CunYbsfgJWDXmpfcvKnoW1G3TBAY6grG"
url <- "https://api.nytimes.com/svc/search/v2/articlesearch.json?q=trump&begin_date=20200101&end_date=20200101&page=1"
req <- fromJSON(paste0(url, key))
articles <- req$response$docs
link = "https://api.nytimes.com/svc/search/v2/articlesearch.json?q=trump"
keys <- c("&api-key=CunYbsfgJWDXmpfcvKnoW1G3TBAY6grG",
"&api-key=gDxQ32ZZfP8KarCN5MrGdmrkeKfkko7u",
"&api-key=Cg6eP60vTxQAEtZoez9YccqiF9CHCyCA",
"&api-key=9fiVSl9AtqEaHqtInQLx3V56dmUgYy27",
"&api-key=kfpVf3ML5uymHzA83Ai5op7AZfQbkjcB",
"&api-key=dfrzINL05mURMbUrnLDGgsNWBlAqVR9n")
dates <- ymd('20200101') + 0:5
d <- format(dates,'%Y%m%d')
totalarticles <- NULL
# for (i in 1:length(keys)) {
#   key = keys[i]
#   for(i in d){
#     p = 0
#     while(p < 10){
#       url = paste0(link, '&begin_date=',i ,'&end_date=',i ,'&page=',p)
#       req <- fromJSON(paste0(url, key))
#       articles <- req$response$docs
#       totalarticles <- bind_rows(totalarticles,articles)
#       if(isTRUE(nrow(articles)) && nrow(articles) != 10){ break }
#       else{p = p+1}
#       Sys.sleep(12)
#     }
#   }
# }
pr = 0
for(i in d){
p = 0
while(p < 10){
key <- keys[pr %% length(keys)+1] #modular arithmetic
#key <- sample(keys, size = 1)
url = paste0(link, '&begin_date=',i ,'&end_date=',i ,'&page=',p)
req <- fromJSON(paste0(url, key))
pr = pr + 1
articles <- req$response$docs
totalarticles <- bind_rows(totalarticles,articles)
if(is.null(nrow(articles)) | (isTRUE(nrow(articles)) && nrow(articles) != 10)){ break }
else{p = p+1}
Sys.sleep(2)
}
}
totalarticles <-  totalarticles %>%
mutate(date = str_trunc(pub_date, width = 10, ellipsis = "")) %>%
filter(date >= "2020-01-01")
# save(totalarticles, file = "trump_guardian.RData")
body_text_tot <- NULL
for (i in 1:length(totalarticles$webUrl)) {
article <- read_html(totalarticles$webUrl[i])
body_text <-
article %>%
html_elements(".css-at9mc1.evys1bk0") %>%
html_text()
body_text_coll<- tibble(url = totalarticles$webUrl[i], text = paste(body_text, collapse = " "))
body_text_tot <- bind_rows(body_text_tot, body_text_coll)
}
View(totalarticles)
View(bidenarticles)
library(jsonlite)
library(tidyverse)
library(lubridate)
library(rvest)
library(readxl)
key <- "&api-key=CunYbsfgJWDXmpfcvKnoW1G3TBAY6grG"
url <- "https://api.nytimes.com/svc/search/v2/articlesearch.json?q=trump&begin_date=20200101&end_date=20200101&page=1"
req <- fromJSON(paste0(url, key))
articles <- req$response$docs
link = "https://api.nytimes.com/svc/search/v2/articlesearch.json?q=trump"
keys <- c("&api-key=CunYbsfgJWDXmpfcvKnoW1G3TBAY6grG",
"&api-key=gDxQ32ZZfP8KarCN5MrGdmrkeKfkko7u",
"&api-key=Cg6eP60vTxQAEtZoez9YccqiF9CHCyCA",
"&api-key=9fiVSl9AtqEaHqtInQLx3V56dmUgYy27",
"&api-key=kfpVf3ML5uymHzA83Ai5op7AZfQbkjcB",
"&api-key=dfrzINL05mURMbUrnLDGgsNWBlAqVR9n")
dates <- ymd('20200101') + 0:5
d <- format(dates,'%Y%m%d')
totalarticles <- NULL
# for (i in 1:length(keys)) {
#   key = keys[i]
#   for(i in d){
#     p = 0
#     while(p < 10){
#       url = paste0(link, '&begin_date=',i ,'&end_date=',i ,'&page=',p)
#       req <- fromJSON(paste0(url, key))
#       articles <- req$response$docs
#       totalarticles <- bind_rows(totalarticles,articles)
#       if(isTRUE(nrow(articles)) && nrow(articles) != 10){ break }
#       else{p = p+1}
#       Sys.sleep(12)
#     }
#   }
# }
pr = 0
for(i in d){
p = 0
while(p < 10){
key <- keys[pr %% length(keys)+1] #modular arithmetic
#key <- sample(keys, size = 1)
url = paste0(link, '&begin_date=',i ,'&end_date=',i ,'&page=',p)
req <- fromJSON(paste0(url, key))
pr = pr + 1
articles <- req$response$docs
totalarticles <- bind_rows(totalarticles,articles)
if(is.null(nrow(articles)) | (isTRUE(nrow(articles)) && nrow(articles) != 10)){ break }
else{p = p+1}
Sys.sleep(2)
}
}
totalarticles <-  totalarticles %>%
mutate(date = str_trunc(pub_date, width = 10, ellipsis = "")) %>%
filter(date >= "2020-01-01")
# save(totalarticles, file = "trump_guardian.RData")
body_text_tot <- NULL
for (i in 1:length(totalarticles$web_url)) {
article <- read_html(totalarticles$web_url[i])
body_text <-
article %>%
html_elements(".css-at9mc1.evys1bk0") %>%
html_text()
body_text_coll<- tibble(url = totalarticles$webb_url[i], text = paste(body_text, collapse = " "))
body_text_tot <- bind_rows(body_text_tot, body_text_coll)
}
save(body_text_tot, file = "trump_nyt.RData")
View(body_text_tot)
View(body_text_tot)
View(body_text_coll)
View(totalarticles)
load("~/Documents/GitHub/comp456/trump_nyt.RData")
load("~/Documents/GitHub/comp456/trump_nyt.RData")
load("~/Documents/GitHub/comp456/trump_nyt.RData")
totalarticles <-  totalarticles %>%
mutate(date = str_trunc(pub_date, width = 10, ellipsis = "")) %>%
filter(date >= "2020-01-01")
load("~/Documents/GitHub/comp456/trump_guardian_2020.RData")
load("~/Documents/GitHub/comp456/Articles Data/trump_guardian.RData")
View(totalarticles)
library(jsonlite)
library(tidyverse)
library(lubridate)
library(rvest)
library(readxl)
key <- "&api-key=CunYbsfgJWDXmpfcvKnoW1G3TBAY6grG"
url <- "https://api.nytimes.com/svc/search/v2/articlesearch.json?q=trump&begin_date=20200101&end_date=20200101&page=1"
req <- fromJSON(paste0(url, key))
articles <- req$response$docs
link = "https://api.nytimes.com/svc/search/v2/articlesearch.json?q=trump"
keys <- c("&api-key=CunYbsfgJWDXmpfcvKnoW1G3TBAY6grG",
"&api-key=gDxQ32ZZfP8KarCN5MrGdmrkeKfkko7u",
"&api-key=Cg6eP60vTxQAEtZoez9YccqiF9CHCyCA",
"&api-key=9fiVSl9AtqEaHqtInQLx3V56dmUgYy27",
"&api-key=kfpVf3ML5uymHzA83Ai5op7AZfQbkjcB",
"&api-key=dfrzINL05mURMbUrnLDGgsNWBlAqVR9n")
dates <- ymd('20200101') + 0:5
d <- format(dates,'%Y%m%d')
totalarticles <- NULL
# for (i in 1:length(keys)) {
#   key = keys[i]
#   for(i in d){
#     p = 0
#     while(p < 10){
#       url = paste0(link, '&begin_date=',i ,'&end_date=',i ,'&page=',p)
#       req <- fromJSON(paste0(url, key))
#       articles <- req$response$docs
#       totalarticles <- bind_rows(totalarticles,articles)
#       if(isTRUE(nrow(articles)) && nrow(articles) != 10){ break }
#       else{p = p+1}
#       Sys.sleep(12)
#     }
#   }
# }
pr = 0
for(i in d){
p = 0
while(p < 10){
key <- keys[pr %% length(keys)+1] #modular arithmetic
#key <- sample(keys, size = 1)
url = paste0(link, '&begin_date=',i ,'&end_date=',i ,'&page=',p)
req <- fromJSON(paste0(url, key))
pr = pr + 1
articles <- req$response$docs
totalarticles <- bind_rows(totalarticles,articles)
if(is.null(nrow(articles)) | (isTRUE(nrow(articles)) && nrow(articles) != 10)){ break }
else{p = p+1}
Sys.sleep(2)
}
}
trumpnyttotal <-  totalarticles %>%
mutate(date = str_trunc(pub_date, width = 10, ellipsis = "")) %>%
filter(date >= "2020-01-01")
# save(trumpnyttotal, file = "trump_guardian.RData")
body_text_tot <- NULL
for (i in 1:length(totalarticles$web_url)) {
article <- read_html(totalarticles$web_url[i])
body_text <-
article %>%
html_elements(".css-at9mc1.evys1bk0") %>%
html_text()
body_text_coll<- tibble(url = totalarticles$webb_url[i], text = paste(body_text, collapse = " "))
body_text_tot <- bind_rows(body_text_tot, body_text_coll)
}
save(body_text_tot, file = "trump_nyt.RData")
View(totalarticles)
View(trumpnyttotal)
View(body_text_coll)
View(body_text_tot)
library(jsonlite)
library(tidyverse)
library(lubridate)
library(rvest)
library(readxl)
key <- "&api-key=CunYbsfgJWDXmpfcvKnoW1G3TBAY6grG"
url <- "https://api.nytimes.com/svc/search/v2/articlesearch.json?q=trump&begin_date=20200101&end_date=20200101&page=1"
req <- fromJSON(paste0(url, key))
articles <- req$response$docs
link = "https://api.nytimes.com/svc/search/v2/articlesearch.json?q=trump"
keys <- c("&api-key=CunYbsfgJWDXmpfcvKnoW1G3TBAY6grG",
"&api-key=gDxQ32ZZfP8KarCN5MrGdmrkeKfkko7u",
"&api-key=Cg6eP60vTxQAEtZoez9YccqiF9CHCyCA",
"&api-key=9fiVSl9AtqEaHqtInQLx3V56dmUgYy27",
"&api-key=kfpVf3ML5uymHzA83Ai5op7AZfQbkjcB",
"&api-key=dfrzINL05mURMbUrnLDGgsNWBlAqVR9n")
dates <- ymd('20200101') + 0:5
d <- format(dates,'%Y%m%d')
totalarticles <- NULL
# for (i in 1:length(keys)) {
#   key = keys[i]
#   for(i in d){
#     p = 0
#     while(p < 10){
#       url = paste0(link, '&begin_date=',i ,'&end_date=',i ,'&page=',p)
#       req <- fromJSON(paste0(url, key))
#       articles <- req$response$docs
#       totalarticles <- bind_rows(totalarticles,articles)
#       if(isTRUE(nrow(articles)) && nrow(articles) != 10){ break }
#       else{p = p+1}
#       Sys.sleep(12)
#     }
#   }
# }
pr = 0
for(i in d){
p = 0
while(p < 10){
key <- keys[pr %% length(keys)+1] #modular arithmetic
#key <- sample(keys, size = 1)
url = paste0(link, '&begin_date=',i ,'&end_date=',i ,'&page=',p)
req <- fromJSON(paste0(url, key))
pr = pr + 1
articles <- req$response$docs
totalarticles <- bind_rows(totalarticles,articles)
if(is.null(nrow(articles)) | (isTRUE(nrow(articles)) && nrow(articles) != 10)){ break }
else{p = p+1}
Sys.sleep(6)
}
}
trumpnyttotal <-  totalarticles %>%
mutate(date = str_trunc(pub_date, width = 10, ellipsis = "")) %>%
filter(date >= "2020-01-01")
# save(trumpnyttotal, file = "trump_guardian.RData")
body_text_tot <- NULL
for (i in 1:length(totalarticles$web_url)) {
article <- read_html(totalarticles$web_url[i])
body_text <-
article %>%
html_elements(".css-at9mc1.evys1bk0") %>%
html_text()
body_text_coll<- tibble(url = totalarticles$webb_url[i], text = paste(body_text, collapse = " "))
body_text_tot <- bind_rows(body_text_tot, body_text_coll)
}
save(body_text_tot, file = "trump_nyt.RData")
View(trumpnyttotal)
View(totalarticles)
