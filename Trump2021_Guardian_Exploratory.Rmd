---
title: "Trump2021_Guardian_Exploratory"
output: html_document
date: "2023-03-28"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(dplyr)
library(lubridate)
library(urltools)
library(scales)
library(textdata)
library(wordcloud)
library(igraph) 
library(ggplot2)
library(tidytext)
library(broom)
library(reshape2)
library(ggraph)
data("stop_words")
mystopwords <- tibble(word = c("trump", "trumps", "trump's","trump’s", "biden", "biden's", "biden’s", "donald", "u.s"))

load("Articles Data/guardian2021.RData")
load("Articles Data/guardian2021_text.RData")
```


```{r}
tidy_body_text_tot <- body_text_tot %>%
  mutate(text = str_remove_all(text, "[:punct:]")) %>% 
  filter(text != "")

tidy_trump <- tidy_body_text_tot %>% 
  unnest_tokens(word, text) %>% 
  anti_join(stop_words) %>% 
  anti_join(mystopwords) %>% 
  count(word, sort = TRUE)

tidy_trump %>% 
  inner_join(get_sentiments("bing")) %>% 
  group_by(sentiment) %>% 
  slice_max(n, n = 10) %>% 
  mutate(word = reorder(word, n)) %>% 
  ggplot(aes(n, word, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(x = "Contribution to sentiment",
       y = NULL)
```

```{r}
tidy_trump %>%
  with(wordcloud(word, n, max.words = 50))
```

```{r}
section_words <- totalarticles %>% 
  select(webUrl, sectionName) %>% 
  rename(url = webUrl) %>% 
  left_join(tidy_body_text_tot, by = "url") %>% 
  unnest_tokens(word, text) %>% 
  count(sectionName, word, sort = TRUE)


tot_words <- section_words %>% 
  group_by(sectionName) %>% 
  summarize(total = sum(n))

section_words <- left_join(section_words, tot_words, by = "sectionName")

section_tf_idf <- section_words %>% 
  bind_tf_idf(word, sectionName, n) %>% 
  arrange(desc(tf_idf))

section_tf_idf %>% 
  filter(sectionName %in% c("US news", "Global development", "Society", "News", "Politics")) %>% 
  group_by(sectionName) %>% 
  slice_max(tf_idf, n = 10) %>% 
  ungroup() %>% 
  ggplot(aes(x = tf_idf, y = fct_reorder(word, tf_idf), fill = sectionName)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sectionName, ncol = 2, scales = "free") +
  labs(x = "tf-idf")

```
```{r}
trump_bigrams <- totalarticles %>% 
  select(webUrl, sectionName) %>% 
  rename(url = webUrl) %>% 
  left_join(body_text_tot, by = "url")  %>% 
  unnest_tokens(bigram, text, token = "ngrams", n = 2) %>% 
  filter(!is.na(bigram))

trump_bigram_sep <- trump_bigrams %>% 
  separate(bigram, c("word1", "word2"), sep = " ")

section_bigram_tf_idf <- trump_bigram_sep %>% 
  filter(!word1 %in% stop_words$word) %>% 
  filter(!word1 %in% mystopwords$word) %>% 
  filter(!word2 %in% stop_words$word) %>% 
  filter(!word2 %in% mystopwords$word) %>% 
  unite(bigram, word1, word2, sep = " ") %>% 
  count(sectionName, bigram, sort = TRUE)

section_bigram_tf_idf %>% 
  bind_tf_idf(bigram, sectionName, n) %>% 
  arrange(desc(tf_idf)) %>% 
  filter(sectionName %in% c("US news", "Global development", "Society", "News", "Politics")) %>% 
  group_by(sectionName) %>% 
  slice_max(tf_idf, n = 10) %>% 
  ungroup() %>% 
  ggplot(aes(x = tf_idf, y = fct_reorder(bigram, tf_idf), fill = sectionName)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sectionName, ncol = 2, scales = "free") +
  labs(x = "tf-idf")

bigram_graph <- trump_bigram_sep %>% 
  filter(!word1 %in% stop_words$word) %>% 
  filter(!word1 %in% mystopwords$word) %>% 
  filter(!word2 %in% stop_words$word) %>% 
  filter(!word2 %in% mystopwords$word) %>% 
  count(word1, word2, sort = TRUE) %>% 
  filter(n > 70) %>% 
  graph_from_data_frame()

set.seed(2020)
a <- grid::arrow(type = "closed", length = unit(.15, "inches"))

ggraph(bigram_graph, layout = "fr") +
  geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
                 arrow = a, end_cap = circle(.07, 'inches')) +
  geom_node_point(color = "lightblue", size = 3) +
  geom_node_text(aes(label = name), vjust = 0.2, hjust = 0.2) +
  theme_void()
```

```{r}
# Making a graph of positive v.s. negative by section on ratio aspect
# TO DO: try it again after you get all the articles from guardian 2021
section_words %>% 
  anti_join(stop_words, by = "word") %>% 
  anti_join(mystopwords, by = "word") %>% 
  inner_join(get_sentiments("bing"), by = "word") %>% # I'm using "bing" package here to count the quant of positive and negative words
  group_by(sectionName, sentiment) %>% 
  summarize(quant = sum(n)) %>% 
  group_by(sectionName) %>% 
  mutate(ratio = quant/sum(quant)) %>% 
  ggplot(aes(x = sectionName, y = ratio, fill = sentiment)) +
  geom_bar(stat = "identity", position = "dodge") + 
  scale_fill_brewer(palette = "Set1") + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
        legend.title = element_blank()) +
  labs(title = "The Guardian View on Trump in 2021",
       subtitle = "The Ratio of Positive & Negative Words by Section ('bing')") +
  xlab("") +
  ylab("Ratio")
  
```

```{r}
# Still a graph of positive v.s. negative by section on ratio aspect
# TO DO: same as above.
section_words %>% 
  anti_join(stop_words, by = "word") %>% 
  anti_join(mystopwords, by = "word") %>% 
  inner_join(get_sentiments("afinn"), by = "word") %>%  # I used "afinn" package here to get the score of each word
  group_by(sectionName, word) %>% 
  summarize(score = n*value) %>% 
  ungroup() %>% 
  mutate(sentiment = ifelse(score > 0, "positive", "negative")) %>% 
  group_by(sectionName, sentiment) %>% 
  summarize(cum_score = sum(abs(score))) %>% 
  mutate(ratio = cum_score/sum(cum_score)) %>% 
  ggplot(aes(x = sectionName, y = ratio, fill = sentiment)) +
  geom_bar(stat = "identity", position = "dodge") + 
  scale_fill_brewer(palette = "Set1") + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
        legend.title = element_blank()) +
  labs(title = "The Guardian View on Trump in 2021",
       subtitle = "The Ratio of Positive & Negative Score by Section ('afinn')") +
  xlab("") +
  ylab("Ratio")
```

```{r}
# Graph of sentiment score by month with package "afinn".
# might wanna combine guardian score with nytimes score and see the comparison in a single graph
# TO DO: pull all the 2021 articles from nytimes and guardian.
tidy_body_text_tot %>% 
  rename(webUrl = url) %>% 
  left_join(totalarticles, by = "webUrl") %>% 
  select(webPublicationDate, text) %>% 
  mutate(date = str_trunc(webPublicationDate, 10, ellipsis = "")) %>% 
  mutate(date = ymd(date)) %>% 
  unnest_tokens(word, text) %>% 
  anti_join(stop_words) %>% 
  anti_join(mystopwords) %>% 
  inner_join(get_sentiments("afinn")) %>% 
  group_by(date) %>% 
  summarize(tot_score = sum(value)) %>% 
  ggplot(aes(x = date, y = tot_score, group = 1)) +
  geom_line() + 
  scale_colour_brewer(palette = "Set1") +
  scale_x_date(date_breaks="1 month", date_labels="%m-%Y") +
  labs(title = "Guardian 2021",
       subtitle = "Sentiment Score for Trump by Month") +
  xlab("") +
  ylab("Score") +
  theme_classic()
```



















